# é˜¶æ®µ 6ï¼šOCR æ³¨å†Œå·è¯†åˆ«

> â±ï¸ é¢„è®¡æ—¶é—´ï¼š3-4 å¤©
> ğŸ¯ ç›®æ ‡ï¼šå®ç°é£æœºæ³¨å†Œå·çš„æ£€æµ‹å’Œè¯†åˆ«
> ğŸ“Œ æ ¸å¿ƒæ¦‚å¿µï¼šæ£€æµ‹ + OCR ä¸¤é˜¶æ®µæµç¨‹

---

## ğŸ“‹ æœ¬é˜¶æ®µæ£€æŸ¥æ¸…å•

å®Œæˆæœ¬é˜¶æ®µåï¼Œä½ éœ€è¦æœ‰ï¼š
- [ ] æ³¨å†Œå·åŒºåŸŸæ£€æµ‹æ¨¡å‹ï¼ˆYOLOv8ï¼‰
- [ ] OCR è¯†åˆ«èƒ½åŠ›ï¼ˆPaddleOCR æˆ–è‡ªè®­ç»ƒï¼‰
- [ ] å®Œæ•´çš„æ£€æµ‹â†’è¯†åˆ« Pipeline
- [ ] æ³¨å†Œå·å®Œå…¨æ­£ç¡®ç‡ > 75%

---

## æ ¸å¿ƒæ¦‚å¿µï¼šä¸ºä»€ä¹ˆ OCR å•ç‹¬åšï¼Ÿ

æ³¨å†Œå·è¯†åˆ«ä¸å›¾åƒåˆ†ç±»æ˜¯å®Œå…¨ä¸åŒçš„ä»»åŠ¡ï¼š

| æ–¹é¢ | å›¾åƒåˆ†ç±» | OCR |
|------|----------|-----|
| è¾“å…¥ | æ•´å¼ å›¾ç‰‡ | æ–‡å­—åŒºåŸŸ |
| è¾“å‡º | å›ºå®šç±»åˆ« | å¯å˜é•¿åº¦å­—ç¬¦ä¸² |
| éš¾ç‚¹ | ç±»é—´å·®å¼‚å° | å­—ç¬¦å˜å½¢ã€é®æŒ¡ |
| æ–¹æ³• | CNN/Transformer | æ£€æµ‹ + åºåˆ—è¯†åˆ« |

### ä¸¤é˜¶æ®µæµç¨‹

```
åŸå§‹å›¾ç‰‡
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ³¨å†Œå·æ£€æµ‹      â”‚  â† YOLOv8 æˆ–ä½ æ ‡æ³¨çš„ registrationarea
â”‚  (å®šä½)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    æ£€æµ‹åˆ°çš„åŒºåŸŸ
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OCR è¯†åˆ«       â”‚  â† PaddleOCR / TrOCR / è‡ªè®­ç»ƒ
â”‚  (è¯†åˆ«æ–‡å­—)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    "B-1234"
```

---

## ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡æ³¨å†Œå·æ£€æµ‹æ•°æ®

### 1.1 ç†è§£ä½ çš„æ ‡æ³¨

ä½ çš„æ•°æ®ä¸­æœ‰ `registrationarea` å­—æ®µï¼Œæ ¼å¼æ˜¯ YOLO æ ¼å¼ï¼š
```
x_center y_center width height
0.85 0.65 0.12 0.04
```

### 1.2 ç”Ÿæˆ YOLO æ£€æµ‹æ•°æ®é›†

```python
# training/scripts/prepare_registration_detection.py
"""å‡†å¤‡æ³¨å†Œå·æ£€æµ‹æ•°æ®é›†"""

import pandas as pd
from pathlib import Path
import shutil
from sklearn.model_selection import train_test_split

def prepare_detection_dataset(
    csv_path: str,
    image_dir: str,
    output_dir: str
):
    """
    å°†æ ‡æ³¨è½¬æ¢ä¸º YOLO æ£€æµ‹æ ¼å¼
    
    YOLO æ ¼å¼ç›®å½•ç»“æ„ï¼š
    output_dir/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/
    â”‚   â””â”€â”€ val/
    â””â”€â”€ labels/
        â”œâ”€â”€ train/
        â””â”€â”€ val/
    """
    output_path = Path(output_dir)
    
    # åˆ›å»ºç›®å½•
    for split in ['train', 'val']:
        (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # è¯»å–æ ‡æ³¨
    df = pd.read_csv(csv_path)
    
    # åªä¿ç•™æœ‰æ³¨å†Œå·åŒºåŸŸæ ‡æ³¨çš„
    df = df[df['registrationarea'].notna() & (df['registrationarea'] != '')]
    print(f"æœ‰æ³¨å†Œå·åŒºåŸŸæ ‡æ³¨çš„å›¾ç‰‡: {len(df)} å¼ ")
    
    if len(df) == 0:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ³¨å†Œå·åŒºåŸŸæ ‡æ³¨ï¼")
        print("  è¯·ç¡®ä¿ CSV ä¸­æœ‰ registrationarea åˆ—")
        return
    
    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯
    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)
    
    image_path = Path(image_dir)
    
    def process_split(split_df, split_name):
        count = 0
        for _, row in split_df.iterrows():
            img_file = image_path / row['filename']
            if not img_file.exists():
                continue
            
            # å¤åˆ¶å›¾ç‰‡
            dst_img = output_path / 'images' / split_name / row['filename']
            shutil.copy2(img_file, dst_img)
            
            # åˆ›å»ºæ ‡ç­¾æ–‡ä»¶
            # YOLO æ ¼å¼: class_id x_center y_center width height
            label_content = f"0 {row['registrationarea']}\n"
            
            label_file = output_path / 'labels' / split_name / (Path(row['filename']).stem + '.txt')
            label_file.write_text(label_content)
            
            count += 1
        
        print(f"  {split_name}: {count} å¼ ")
        return count
    
    print("\nç”Ÿæˆæ£€æµ‹æ•°æ®é›†:")
    process_split(train_df, 'train')
    process_split(val_df, 'val')
    
    # åˆ›å»º YOLO é…ç½®æ–‡ä»¶
    yaml_content = f"""
# Registration Detection Dataset
path: {output_path.absolute()}
train: images/train
val: images/val

# Classes
names:
  0: registration
"""
    
    yaml_path = output_path / 'dataset.yaml'
    yaml_path.write_text(yaml_content)
    print(f"\nâœ… æ•°æ®é›†é…ç½®: {yaml_path}")


if __name__ == "__main__":
    prepare_detection_dataset(
        csv_path="training/data/labels/aircraft_labels.csv",
        image_dir="training/data/processed/aircraft_crop/train",
        output_dir="training/data/registration_detection"
    )
```

---

## ç¬¬äºŒæ­¥ï¼šè®­ç»ƒæ³¨å†Œå·æ£€æµ‹æ¨¡å‹

### 2.1 ä½¿ç”¨ YOLOv8 è®­ç»ƒ

```python
# training/scripts/train_registration_detector.py
"""è®­ç»ƒæ³¨å†Œå·æ£€æµ‹æ¨¡å‹"""

from ultralytics import YOLO
from pathlib import Path

def train_detector():
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8m.pt')  # ä¸­ç­‰å¤§å°
    
    # è®­ç»ƒ
    results = model.train(
        data='training/data/registration_detection/dataset.yaml',
        epochs=50,
        imgsz=640,
        batch=16,
        name='registration_detector',
        project='training/checkpoints/stage6',
        
        # æ•°æ®å¢å¼ºï¼ˆæ–‡å­—æ£€æµ‹ä¸è¦å¤ªæ¿€è¿›çš„å¢å¼ºï¼‰
        hsv_h=0.01,
        hsv_s=0.3,
        hsv_v=0.3,
        degrees=5,
        translate=0.1,
        scale=0.2,
        fliplr=0.0,  # ä¸è¦å·¦å³ç¿»è½¬ï¼ˆä¼šå½±å“æ–‡å­—æ–¹å‘ï¼‰
        flipud=0.0,
        mosaic=0.5,
    )
    
    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æ¨¡å‹: training/checkpoints/stage6/registration_detector/weights/best.pt")


if __name__ == "__main__":
    train_detector()
```

### 2.2 æµ‹è¯•æ£€æµ‹æ•ˆæœ

```python
# training/scripts/test_registration_detector.py
"""æµ‹è¯•æ³¨å†Œå·æ£€æµ‹"""

from ultralytics import YOLO
from pathlib import Path
import matplotlib.pyplot as plt
from PIL import Image

def test_detector(model_path: str, image_dir: str, n_samples: int = 10):
    model = YOLO(model_path)
    
    image_path = Path(image_dir)
    images = list(image_path.glob("*.jpg"))[:n_samples]
    
    fig, axes = plt.subplots(2, 5, figsize=(20, 8))
    axes = axes.flatten()
    
    for ax, img_file in zip(axes, images):
        # æ£€æµ‹
        results = model(str(img_file), verbose=False)[0]
        
        # æ˜¾ç¤ºç»“æœ
        img = Image.open(img_file)
        ax.imshow(img)
        
        # ç”»æ¡†
        for box in results.boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            conf = box.conf[0].cpu().item()
            
            rect = plt.Rectangle(
                (x1, y1), x2-x1, y2-y1,
                fill=False, color='red', linewidth=2
            )
            ax.add_patch(rect)
            ax.text(x1, y1-5, f'{conf:.2f}', color='red', fontsize=8)
        
        ax.set_title(img_file.name[:15])
        ax.axis('off')
    
    plt.tight_layout()
    plt.savefig('training/logs/registration_detection_test.png', dpi=150)
    print("ç»“æœä¿å­˜åˆ° training/logs/registration_detection_test.png")


if __name__ == "__main__":
    test_detector(
        model_path="training/checkpoints/stage6/registration_detector/weights/best.pt",
        image_dir="training/data/processed/aircraft_crop/val"
    )
```

---

## ç¬¬ä¸‰æ­¥ï¼šOCR è¯†åˆ«

### 3.1 æ–¹æ¡ˆé€‰æ‹©

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **PaddleOCR** | å¼€ç®±å³ç”¨ã€æ•ˆæœå¥½ | æ¨¡å‹è¾ƒå¤§ | å¿«é€Ÿå®ç° |
| **EasyOCR** | ç®€å•æ˜“ç”¨ | å‡†ç¡®ç‡ç¨ä½ | ç®€å•åœºæ™¯ |
| **TrOCR** | æ•ˆæœå¥½ | éœ€è¦å¾®è°ƒ | é«˜ç²¾åº¦éœ€æ±‚ |
| **è‡ªè®­ç»ƒ CRNN** | å®Œå…¨å¯æ§ | éœ€è¦å¤§é‡æ•°æ® | ç‰¹æ®Šå­—ä½“ |

### 3.2 ä½¿ç”¨ PaddleOCRï¼ˆæ¨èï¼‰

```python
# training/src/ocr/paddle_ocr.py
"""ä½¿ç”¨ PaddleOCR è¯†åˆ«æ³¨å†Œå·"""

from paddleocr import PaddleOCR
import re

class RegistrationOCR:
    """æ³¨å†Œå· OCR è¯†åˆ«å™¨"""
    
    def __init__(self, use_gpu: bool = True):
        self.ocr = PaddleOCR(
            use_angle_cls=True,  # ä½¿ç”¨æ–¹å‘åˆ†ç±»
            lang='en',           # è‹±æ–‡ï¼ˆæ³¨å†Œå·æ˜¯å­—æ¯+æ•°å­—ï¼‰
            use_gpu=use_gpu,
            show_log=False
        )
        
        # æ³¨å†Œå·æ ¼å¼æ­£åˆ™ï¼ˆæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
        # ä¸­å›½: B-xxxx
        # ç¾å›½: N xxxxx
        # æ¬§æ´²: å„ç§æ ¼å¼
        self.patterns = [
            r'B-\d{4}',           # ä¸­å›½
            r'B-\d{3}[A-Z]',      # ä¸­å›½
            r'N\d{1,5}[A-Z]{0,2}', # ç¾å›½
            r'[A-Z]-[A-Z]{4}',    # æ¬§æ´²
            r'[A-Z]{2}-[A-Z]{3}', # æ¬§æ´²
        ]
    
    def recognize(self, image):
        """
        è¯†åˆ«å›¾ç‰‡ä¸­çš„æ³¨å†Œå·
        
        Args:
            image: PIL Image æˆ– numpy array æˆ– æ–‡ä»¶è·¯å¾„
        
        Returns:
            str: è¯†åˆ«çš„æ³¨å†Œå·ï¼Œæœªè¯†åˆ«åˆ°è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        result = self.ocr.ocr(image, cls=True)
        
        if not result or not result[0]:
            return ""
        
        # åˆå¹¶æ‰€æœ‰è¯†åˆ«æ–‡æœ¬
        texts = []
        for line in result[0]:
            text = line[1][0]  # æ–‡æœ¬å†…å®¹
            conf = line[1][1]  # ç½®ä¿¡åº¦
            if conf > 0.5:
                texts.append(text.upper().replace(' ', ''))
        
        full_text = ''.join(texts)
        
        # å°è¯•åŒ¹é…æ³¨å†Œå·æ ¼å¼
        for pattern in self.patterns:
            match = re.search(pattern, full_text)
            if match:
                return match.group()
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡å‡†æ ¼å¼ï¼Œè¿”å›æ¸…ç†åçš„æ–‡æœ¬
        # åªä¿ç•™å­—æ¯ã€æ•°å­—å’Œè¿å­—ç¬¦
        cleaned = re.sub(r'[^A-Z0-9-]', '', full_text)
        return cleaned if len(cleaned) >= 4 else ""
    
    def recognize_with_confidence(self, image):
        """è¯†åˆ«å¹¶è¿”å›ç½®ä¿¡åº¦"""
        result = self.ocr.ocr(image, cls=True)
        
        if not result or not result[0]:
            return "", 0.0
        
        texts = []
        confs = []
        for line in result[0]:
            texts.append(line[1][0])
            confs.append(line[1][1])
        
        full_text = ''.join(texts).upper().replace(' ', '')
        avg_conf = sum(confs) / len(confs) if confs else 0.0
        
        # æ¸…ç†
        cleaned = re.sub(r'[^A-Z0-9-]', '', full_text)
        
        return cleaned, avg_conf
```

### 3.3 å®Œæ•´ Pipeline

```python
# training/src/ocr/pipeline.py
"""æ³¨å†Œå·è¯†åˆ«å®Œæ•´ Pipeline"""

from ultralytics import YOLO
from PIL import Image
import numpy as np
from pathlib import Path

class RegistrationPipeline:
    """
    æ³¨å†Œå·è¯†åˆ« Pipeline
    
    æµç¨‹: æ£€æµ‹ â†’ è£å‰ª â†’ OCR
    """
    
    def __init__(
        self,
        detector_path: str,
        use_gpu: bool = True
    ):
        # åŠ è½½æ£€æµ‹æ¨¡å‹
        self.detector = YOLO(detector_path)
        
        # åŠ è½½ OCR
        from .paddle_ocr import RegistrationOCR
        self.ocr = RegistrationOCR(use_gpu=use_gpu)
        
        print("âœ… Pipeline åˆå§‹åŒ–å®Œæˆ")
    
    def process(self, image, conf_threshold: float = 0.5):
        """
        å¤„ç†å•å¼ å›¾ç‰‡
        
        Args:
            image: PIL Imageã€numpy array æˆ–æ–‡ä»¶è·¯å¾„
        
        Returns:
            dict: {
                'registration': str,  # è¯†åˆ«ç»“æœ
                'confidence': float,  # ç½®ä¿¡åº¦
                'bbox': list,         # æ£€æµ‹æ¡† [x1, y1, x2, y2]
            }
        """
        # åŠ è½½å›¾ç‰‡
        if isinstance(image, (str, Path)):
            img = Image.open(image)
        elif isinstance(image, np.ndarray):
            img = Image.fromarray(image)
        else:
            img = image
        
        # æ£€æµ‹æ³¨å†Œå·åŒºåŸŸ
        results = self.detector(img, verbose=False)[0]
        
        if len(results.boxes) == 0:
            return {
                'registration': '',
                'confidence': 0.0,
                'bbox': None,
                'detected': False
            }
        
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹æ¡†
        best_idx = results.boxes.conf.argmax()
        box = results.boxes.xyxy[best_idx].cpu().numpy()
        det_conf = results.boxes.conf[best_idx].cpu().item()
        
        if det_conf < conf_threshold:
            return {
                'registration': '',
                'confidence': 0.0,
                'bbox': None,
                'detected': False
            }
        
        # è£å‰ªåŒºåŸŸï¼ˆç¨å¾®æ‰©å¤§ä¸€ç‚¹ï¼‰
        x1, y1, x2, y2 = box
        w, h = x2 - x1, y2 - y1
        padding = 0.1
        
        x1 = max(0, x1 - w * padding)
        y1 = max(0, y1 - h * padding)
        x2 = min(img.width, x2 + w * padding)
        y2 = min(img.height, y2 + h * padding)
        
        crop = img.crop((int(x1), int(y1), int(x2), int(y2)))
        
        # OCR è¯†åˆ«
        text, ocr_conf = self.ocr.recognize_with_confidence(np.array(crop))
        
        # ç»¼åˆç½®ä¿¡åº¦
        final_conf = det_conf * ocr_conf
        
        return {
            'registration': text,
            'confidence': final_conf,
            'bbox': [x1, y1, x2, y2],
            'detected': True
        }
    
    def process_batch(self, images):
        """æ‰¹é‡å¤„ç†"""
        return [self.process(img) for img in images]
```

---

## ç¬¬å››æ­¥ï¼šè¯„ä¼° OCR æ•ˆæœ

```python
# training/scripts/evaluate_ocr.py
"""è¯„ä¼° OCR æ•ˆæœ"""

import sys
sys.path.append('training/src')

import pandas as pd
from pathlib import Path
from tqdm import tqdm

def evaluate_ocr(pipeline, csv_path: str, image_dir: str):
    """è¯„ä¼° OCR å‡†ç¡®ç‡"""
    
    df = pd.read_csv(csv_path)
    
    # åªè¯„ä¼°æœ‰æ³¨å†Œå·æ ‡æ³¨çš„
    df = df[df['registration'].notna() & (df['registration'] != '')]
    print(f"è¯„ä¼°æ ·æœ¬æ•°: {len(df)}")
    
    correct = 0
    detected = 0
    char_correct = 0
    char_total = 0
    
    results = []
    
    for _, row in tqdm(df.iterrows(), total=len(df)):
        img_path = Path(image_dir) / row['filename']
        if not img_path.exists():
            continue
        
        # é¢„æµ‹
        pred = pipeline.process(str(img_path))
        
        # çœŸå®å€¼
        gt = row['registration'].upper().replace(' ', '')
        pred_text = pred['registration']
        
        # ç»Ÿè®¡
        if pred['detected']:
            detected += 1
        
        if pred_text == gt:
            correct += 1
        
        # å­—ç¬¦çº§å‡†ç¡®ç‡
        for i, c in enumerate(gt):
            char_total += 1
            if i < len(pred_text) and pred_text[i] == c:
                char_correct += 1
        
        results.append({
            'filename': row['filename'],
            'ground_truth': gt,
            'prediction': pred_text,
            'correct': pred_text == gt,
            'confidence': pred['confidence']
        })
    
    # ç»Ÿè®¡
    total = len(df)
    detection_rate = detected / total if total > 0 else 0
    accuracy = correct / total if total > 0 else 0
    char_accuracy = char_correct / char_total if char_total > 0 else 0
    
    print("\n" + "=" * 50)
    print("OCR è¯„ä¼°ç»“æœ")
    print("=" * 50)
    print(f"æ£€æµ‹ç‡: {detection_rate:.2%} ({detected}/{total})")
    print(f"å®Œå…¨æ­£ç¡®ç‡: {accuracy:.2%} ({correct}/{total})")
    print(f"å­—ç¬¦å‡†ç¡®ç‡: {char_accuracy:.2%}")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_df = pd.DataFrame(results)
    results_df.to_csv('training/logs/ocr_evaluation.csv', index=False)
    print(f"\nè¯¦ç»†ç»“æœä¿å­˜åˆ°: training/logs/ocr_evaluation.csv")
    
    # æ˜¾ç¤ºé”™è¯¯æ ·ä¾‹
    errors = results_df[~results_df['correct']].head(10)
    if len(errors) > 0:
        print("\né”™è¯¯æ ·ä¾‹:")
        for _, row in errors.iterrows():
            print(f"  {row['filename']}: GT={row['ground_truth']}, Pred={row['prediction']}")
    
    return accuracy, char_accuracy


if __name__ == "__main__":
    from ocr.pipeline import RegistrationPipeline
    
    pipeline = RegistrationPipeline(
        detector_path="training/checkpoints/stage6/registration_detector/weights/best.pt"
    )
    
    evaluate_ocr(
        pipeline,
        csv_path="training/data/processed/aircraft_crop/test.csv",
        image_dir="training/data/processed/aircraft_crop/test"
    )
```

---

## âœ… è¿‡å…³æ ‡å‡†

- [ ] æ³¨å†Œå·æ£€æµ‹ç‡ > 90%
- [ ] æ³¨å†Œå·å®Œå…¨æ­£ç¡®ç‡ > 75%
- [ ] å­—ç¬¦å‡†ç¡®ç‡ > 95%
- [ ] Pipeline èƒ½ç«¯åˆ°ç«¯è¿è¡Œ

---

## âŒ ç¦æ­¢äº‹é¡¹

- âŒ ç”¨åˆ†ç±»æ–¹æ³•åš OCRï¼ˆæŠŠæ¯ä¸ªå­—ç¬¦å½“æˆç±»åˆ«ï¼‰
- âŒ ä¸åšæ£€æµ‹ç›´æ¥å¯¹æ•´å›¾ OCR
- âŒ å¿½ç•¥æ³¨å†Œå·æ ¼å¼æ ¡éªŒ

---

## ğŸ’¡ æå‡æŠ€å·§

### æ•°æ®å¢å¼º

```python
# é’ˆå¯¹ OCR çš„æ•°æ®å¢å¼º
import albumentations as A

ocr_augment = A.Compose([
    A.RandomBrightnessContrast(p=0.5),
    A.GaussNoise(var_limit=(10, 30), p=0.3),
    A.MotionBlur(blur_limit=3, p=0.2),
    A.Perspective(scale=(0.02, 0.05), p=0.3),
])
```

### åå¤„ç†

```python
def postprocess_registration(text):
    """åå¤„ç†æ³¨å†Œå·"""
    # å¸¸è§ OCR é”™è¯¯ä¿®æ­£
    corrections = {
        'O': '0',  # O â†’ 0
        'I': '1',  # I â†’ 1
        'S': '5',  # S â†’ 5
        'Z': '2',  # Z â†’ 2
    }
    
    # åªåœ¨æ•°å­—ä½ç½®åšæ›¿æ¢
    # ä¾‹å¦‚ B-1234 ä¸­çš„ 1234 éƒ¨åˆ†
    # ...
    
    return text
```

---

## ğŸ”œ ä¸‹ä¸€æ­¥

å®Œæˆæ‰€æœ‰æ£€æŸ¥é¡¹åï¼Œè¿›å…¥ [é˜¶æ®µ 7ï¼šè”åˆé›†æˆ](stage7_integration.md)

