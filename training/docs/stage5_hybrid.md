# é˜¶æ®µ 5ï¼šHybrid æ¨¡å‹èåˆ

> â±ï¸ é¢„è®¡æ—¶é—´ï¼š2-3 å¤©
> ğŸ¯ ç›®æ ‡ï¼šèåˆ ConvNeXt å’Œ Swin Transformer çš„ç‰¹å¾ï¼Œæå‡æ¨¡å‹è¡¨ç°
> ğŸ“Œ æ ¸å¿ƒæ¦‚å¿µï¼šCNN + Transformer äº’è¡¥

---

## ğŸ“‹ æœ¬é˜¶æ®µæ£€æŸ¥æ¸…å•

å®Œæˆæœ¬é˜¶æ®µåï¼Œä½ éœ€è¦æœ‰ï¼š
- [ ] ç†è§£ CNN å’Œ Transformer çš„åŒºåˆ«
- [ ] Hybrid æ¨¡å‹èƒ½æ­£å¸¸è¿è¡Œ
- [ ] ç›¸æ¯”é˜¶æ®µ 4ï¼Œå‡†ç¡®ç‡æœ‰æå‡ï¼ˆè‡³å°‘ 1-2%ï¼‰
- [ ] æ¨¡å‹å¤§å°å’Œæ¨ç†é€Ÿåº¦åœ¨å¯æ¥å—èŒƒå›´

---

## æ ¸å¿ƒæ¦‚å¿µï¼šä¸ºä»€ä¹ˆè¦ Hybridï¼Ÿ

### CNN vs Transformer

| ç‰¹æ€§ | CNN (ConvNeXt) | Transformer (Swin) |
|------|----------------|-------------------|
| å½’çº³åç½® | å±€éƒ¨æ€§ã€å¹³ç§»ç­‰å˜æ€§ | è¾ƒå°‘å½’çº³åç½® |
| æ„Ÿå—é‡ | é€å±‚æ‰©å¤§ï¼ˆå±€éƒ¨â†’å…¨å±€ï¼‰ | ä¸€å¼€å§‹å°±èƒ½çœ‹å…¨å±€ |
| æ“…é•¿ | çº¹ç†ã€è¾¹ç¼˜ã€å±€éƒ¨ç‰¹å¾ | å½¢çŠ¶ã€ç»“æ„ã€å…¨å±€å…³ç³» |
| è®¡ç®—æ•ˆç‡ | è¾ƒé«˜ | è¾ƒä½ |
| æ•°æ®éœ€æ±‚ | è¾ƒå°‘ | è¾ƒå¤š |

### ä¸ºä»€ä¹ˆèåˆæœ‰æ•ˆï¼Ÿ

```
é£æœºè¯†åˆ«éœ€è¦ï¼š
â”œâ”€â”€ å±€éƒ¨ç‰¹å¾ï¼ˆCNN æ“…é•¿ï¼‰
â”‚   â”œâ”€â”€ å‘åŠ¨æœºå½¢çŠ¶
â”‚   â”œâ”€â”€ ç¿¼å°–å°ç¿¼ç»†èŠ‚
â”‚   â”œâ”€â”€ èˆ±é—¨æ•°é‡å’Œä½ç½®
â”‚   â””â”€â”€ æ¶‚è£…é¢œè‰²çº¹ç†
â”‚
â””â”€â”€ å…¨å±€ç‰¹å¾ï¼ˆTransformer æ“…é•¿ï¼‰
    â”œâ”€â”€ æœºèº«é•¿å®½æ¯”
    â”œâ”€â”€ æœºç¿¼å½¢çŠ¶
    â”œâ”€â”€ æ•´ä½“è½®å»“
    â””â”€â”€ éƒ¨ä»¶é—´çš„ç©ºé—´å…³ç³»
```

### Hybrid æ¶æ„

```
                    è¾“å…¥å›¾ç‰‡
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                         â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  ConvNeXt â”‚            â”‚   Swin    â”‚
    â”‚  Backbone â”‚            â”‚  Backbone â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                         â”‚
     [B, 1024]                 [B, 1024]
          â”‚                         â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                  â”‚ Fusion  â”‚  â† ç‰¹å¾èåˆ
                  â”‚ Module  â”‚
                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                       â”‚
                  [B, 2048] æˆ– [B, 1024]
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚            â”‚            â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚  Type   â”‚ â”‚ Clarity â”‚ â”‚  ...    â”‚
     â”‚  Head   â”‚ â”‚  Head   â”‚ â”‚         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ç¬¬ä¸€æ­¥ï¼šå®ç° Hybrid æ¨¡å‹

### 1.1 åŸºç¡€ Hybrid æ¨¡å‹

```python
# training/src/models/hybrid.py
"""Hybrid æ¨¡å‹ï¼šConvNeXt + Swin Transformer"""

import torch
import torch.nn as nn
import timm

class HybridModel(nn.Module):
    """
    æ··åˆæ¨¡å‹ï¼šç»“åˆ CNN å’Œ Transformer çš„ä¼˜åŠ¿
    
    Args:
        num_types: æœºå‹ç±»åˆ«æ•°
        num_airlines: èˆªå¸ç±»åˆ«æ•°
        cnn_backbone: CNN éª¨å¹²ç½‘ç»œåç§°
        transformer_backbone: Transformer éª¨å¹²ç½‘ç»œåç§°
        fusion_method: èåˆæ–¹æ³• 'concat' | 'add' | 'attention'
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        dropout: Dropout æ¯”ä¾‹
    """
    
    def __init__(
        self,
        num_types: int,
        num_airlines: int,
        cnn_backbone: str = "convnext_base",
        transformer_backbone: str = "swin_base_patch4_window7_224",
        fusion_method: str = "concat",
        pretrained: bool = True,
        dropout: float = 0.3
    ):
        super().__init__()
        
        self.fusion_method = fusion_method
        
        # ===== ä¸¤ä¸ª Backbone =====
        print(f"åŠ è½½ CNN backbone: {cnn_backbone}")
        self.cnn_backbone = timm.create_model(
            cnn_backbone,
            pretrained=pretrained,
            num_classes=0
        )
        self.cnn_dim = self.cnn_backbone.num_features
        
        print(f"åŠ è½½ Transformer backbone: {transformer_backbone}")
        self.transformer_backbone = timm.create_model(
            transformer_backbone,
            pretrained=pretrained,
            num_classes=0
        )
        self.transformer_dim = self.transformer_backbone.num_features
        
        print(f"  CNN ç‰¹å¾ç»´åº¦: {self.cnn_dim}")
        print(f"  Transformer ç‰¹å¾ç»´åº¦: {self.transformer_dim}")
        
        # ===== ç‰¹å¾èåˆ =====
        if fusion_method == "concat":
            self.fused_dim = self.cnn_dim + self.transformer_dim
            self.fusion = None  # ç›´æ¥æ‹¼æ¥
        
        elif fusion_method == "add":
            # éœ€è¦æŠ•å½±åˆ°ç›¸åŒç»´åº¦
            assert self.cnn_dim == self.transformer_dim, \
                f"add èåˆè¦æ±‚ç»´åº¦ç›¸åŒ: {self.cnn_dim} vs {self.transformer_dim}"
            self.fused_dim = self.cnn_dim
            self.fusion = None
        
        elif fusion_method == "attention":
            # ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶èåˆ
            self.fused_dim = self.cnn_dim  # è¾“å‡ºä¸ CNN ç»´åº¦ç›¸åŒ
            self.fusion = FusionAttention(self.cnn_dim, self.transformer_dim)
        
        else:
            raise ValueError(f"æœªçŸ¥èåˆæ–¹æ³•: {fusion_method}")
        
        print(f"èåˆæ–¹æ³•: {fusion_method}, èåˆåç»´åº¦: {self.fused_dim}")
        
        # ===== ä»»åŠ¡ Head =====
        # åˆ†ç±»
        self.type_head = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(self.fused_dim, num_types)
        )
        
        self.airline_head = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(self.fused_dim, num_airlines)
        )
        
        # å›å½’
        self.clarity_head = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(self.fused_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        self.block_head = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(self.fused_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
        
        self.num_types = num_types
        self.num_airlines = num_airlines
    
    def forward(self, x):
        # æå–ä¸¤ä¸ª backbone çš„ç‰¹å¾
        cnn_features = self.cnn_backbone(x)          # [B, cnn_dim]
        transformer_features = self.transformer_backbone(x)  # [B, transformer_dim]
        
        # èåˆ
        if self.fusion_method == "concat":
            fused = torch.cat([cnn_features, transformer_features], dim=1)
        elif self.fusion_method == "add":
            fused = cnn_features + transformer_features
        elif self.fusion_method == "attention":
            fused = self.fusion(cnn_features, transformer_features)
        
        # å„ä»»åŠ¡é¢„æµ‹
        return {
            'type': self.type_head(fused),
            'airline': self.airline_head(fused),
            'clarity': self.clarity_head(fused).squeeze(-1),
            'block': self.block_head(fused).squeeze(-1),
        }
    
    def get_features(self, x):
        """è¿”å›èåˆåçš„ç‰¹å¾"""
        cnn_features = self.cnn_backbone(x)
        transformer_features = self.transformer_backbone(x)
        
        if self.fusion_method == "concat":
            return torch.cat([cnn_features, transformer_features], dim=1)
        elif self.fusion_method == "add":
            return cnn_features + transformer_features
        elif self.fusion_method == "attention":
            return self.fusion(cnn_features, transformer_features)


class FusionAttention(nn.Module):
    """æ³¨æ„åŠ›èåˆæ¨¡å—"""
    
    def __init__(self, cnn_dim: int, transformer_dim: int, hidden_dim: int = 256):
        super().__init__()
        
        # æŠ•å½±åˆ°ç›¸åŒç»´åº¦
        self.cnn_proj = nn.Linear(cnn_dim, hidden_dim)
        self.trans_proj = nn.Linear(transformer_dim, hidden_dim)
        
        # æ³¨æ„åŠ›æƒé‡
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 2),
            nn.Softmax(dim=1)
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Linear(hidden_dim, cnn_dim)
    
    def forward(self, cnn_feat, trans_feat):
        # æŠ•å½±
        cnn_proj = self.cnn_proj(cnn_feat)      # [B, hidden]
        trans_proj = self.trans_proj(trans_feat)  # [B, hidden]
        
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        combined = torch.cat([cnn_proj, trans_proj], dim=1)  # [B, hidden*2]
        weights = self.attention(combined)  # [B, 2]
        
        # åŠ æƒèåˆ
        w_cnn = weights[:, 0:1]   # [B, 1]
        w_trans = weights[:, 1:2]  # [B, 1]
        
        fused = w_cnn * cnn_proj + w_trans * trans_proj  # [B, hidden]
        
        # è¾“å‡º
        return self.output_proj(fused)
```

### 1.2 æµ‹è¯• Hybrid æ¨¡å‹

```python
# training/scripts/test_hybrid.py
"""æµ‹è¯• Hybrid æ¨¡å‹"""

import sys
sys.path.append('training/src')

import torch
from models.hybrid import HybridModel

def test():
    print("æµ‹è¯• Hybrid æ¨¡å‹...")
    
    # æµ‹è¯•ä¸åŒèåˆæ–¹æ³•
    for fusion in ['concat', 'attention']:
        print(f"\n--- èåˆæ–¹æ³•: {fusion} ---")
        
        model = HybridModel(
            num_types=10,
            num_airlines=12,
            cnn_backbone="convnext_base",
            transformer_backbone="swin_base_patch4_window7_224",
            fusion_method=fusion
        )
        
        # å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"æ€»å‚æ•°é‡: {total_params / 1e6:.2f}M")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(2, 3, 224, 224)
        
        model.eval()
        with torch.no_grad():
            outputs = model(x)
        
        print(f"è¾“å‡ºå½¢çŠ¶:")
        for k, v in outputs.items():
            print(f"  {k}: {v.shape}")
    
    print("\nâœ… Hybrid æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")

if __name__ == "__main__":
    test()
```

---

## ç¬¬äºŒæ­¥ï¼šè®­ç»ƒç­–ç•¥

### 2.1 åˆ†é˜¶æ®µè®­ç»ƒï¼ˆæ¨èï¼‰

ç”±äº Hybrid æ¨¡å‹å‚æ•°é‡å¤§ï¼Œå»ºè®®åˆ†é˜¶æ®µè®­ç»ƒï¼š

```python
# é˜¶æ®µ Aï¼šå†»ç»“ Backboneï¼Œåªè®­ç»ƒ Headï¼ˆ5 epochsï¼‰
for param in model.cnn_backbone.parameters():
    param.requires_grad = False
for param in model.transformer_backbone.parameters():
    param.requires_grad = False

# é˜¶æ®µ Bï¼šè§£å†» Transformerï¼Œå¾®è°ƒï¼ˆ10 epochsï¼‰
for param in model.transformer_backbone.parameters():
    param.requires_grad = True

# é˜¶æ®µ Cï¼šå…¨éƒ¨è§£å†»ï¼Œå°å­¦ä¹ ç‡å¾®è°ƒï¼ˆ15 epochsï¼‰
for param in model.cnn_backbone.parameters():
    param.requires_grad = True
```

### 2.2 è®­ç»ƒè„šæœ¬

```python
# training/scripts/train_stage5.py
"""é˜¶æ®µ 5 è®­ç»ƒè„šæœ¬ï¼šHybrid æ¨¡å‹"""

import sys
sys.path.append('training/src')

import torch
from torch.utils.data import DataLoader

from data.dataset import AircraftDataset, full_task_collate_fn
from data.transforms import get_train_transform, get_val_transform, AlbumentationsWrapper
from models.hybrid import HybridModel
from trainers.full_trainer import FullMultiTaskTrainer

def freeze_backbone(model, freeze_cnn=True, freeze_transformer=True):
    """å†»ç»“ backbone"""
    for param in model.cnn_backbone.parameters():
        param.requires_grad = not freeze_cnn
    for param in model.transformer_backbone.parameters():
        param.requires_grad = not freeze_transformer
    
    # ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total = sum(p.numel() for p in model.parameters())
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable/1e6:.2f}M / {total/1e6:.2f}M")

def main():
    config = {
        # æ•°æ®
        'train_csv': 'training/data/processed/aircraft_crop/train.csv',
        'val_csv': 'training/data/processed/aircraft_crop/val.csv',
        'train_dir': 'training/data/processed/aircraft_crop/train',
        'val_dir': 'training/data/processed/aircraft_crop/val',
        'image_size': 224,
        'batch_size': 16,  # Hybrid æ¨¡å‹æ›´å¤§ï¼Œå‡å° batch
        'num_workers': 4,
        
        # æ¨¡å‹
        'cnn_backbone': 'convnext_base',
        'transformer_backbone': 'swin_base_patch4_window7_224',
        'fusion_method': 'concat',
        'dropout': 0.3,
        
        # è®­ç»ƒ
        'epochs': 30,
        'lr': 5e-5,  # Hybrid ç”¨æ›´å°çš„å­¦ä¹ ç‡
        'weight_decay': 0.01,
        
        # ä»»åŠ¡æƒé‡
        'type_weight': 1.0,
        'airline_weight': 0.5,
        'clarity_weight': 0.3,
        'block_weight': 0.3,
        
        'save_dir': 'training/checkpoints/stage5',
    }
    
    # æ•°æ®åŠ è½½
    train_transform = AlbumentationsWrapper(get_train_transform(config['image_size']))
    val_transform = AlbumentationsWrapper(get_val_transform(config['image_size']))
    
    train_dataset = AircraftDataset(
        csv_path=config['train_csv'],
        image_dir=config['train_dir'],
        transform=train_transform,
        task='full'
    )
    
    val_dataset = AircraftDataset(
        csv_path=config['val_csv'],
        image_dir=config['val_dir'],
        transform=val_transform,
        task='full'
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers'],
        pin_memory=True,
        collate_fn=full_task_collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True,
        collate_fn=full_task_collate_fn
    )
    
    # åˆ›å»ºæ¨¡å‹
    model = HybridModel(
        num_types=train_dataset.num_types,
        num_airlines=train_dataset.num_airlines,
        cnn_backbone=config['cnn_backbone'],
        transformer_backbone=config['transformer_backbone'],
        fusion_method=config['fusion_method'],
        dropout=config['dropout']
    )
    
    # ===== åˆ†é˜¶æ®µè®­ç»ƒ =====
    
    # é˜¶æ®µ Aï¼šå†»ç»“ backboneï¼Œè®­ç»ƒ Head
    print("\n" + "="*60)
    print("é˜¶æ®µ Aï¼šè®­ç»ƒ Headï¼ˆå†»ç»“ Backboneï¼‰")
    print("="*60)
    
    freeze_backbone(model, freeze_cnn=True, freeze_transformer=True)
    
    config_a = config.copy()
    config_a['epochs'] = 5
    config_a['lr'] = 1e-3
    config_a['save_dir'] = 'training/checkpoints/stage5/phase_a'
    
    trainer_a = FullMultiTaskTrainer(model, train_loader, val_loader, config_a)
    trainer_a.train()
    
    # é˜¶æ®µ Bï¼šè§£å†» Transformer
    print("\n" + "="*60)
    print("é˜¶æ®µ Bï¼šå¾®è°ƒ Transformer")
    print("="*60)
    
    freeze_backbone(model, freeze_cnn=True, freeze_transformer=False)
    
    config_b = config.copy()
    config_b['epochs'] = 10
    config_b['lr'] = 5e-5
    config_b['save_dir'] = 'training/checkpoints/stage5/phase_b'
    
    trainer_b = FullMultiTaskTrainer(model, train_loader, val_loader, config_b)
    trainer_b.train()
    
    # é˜¶æ®µ Cï¼šå…¨éƒ¨è§£å†»
    print("\n" + "="*60)
    print("é˜¶æ®µ Cï¼šå…¨æ¨¡å‹å¾®è°ƒ")
    print("="*60)
    
    freeze_backbone(model, freeze_cnn=False, freeze_transformer=False)
    
    config_c = config.copy()
    config_c['epochs'] = 15
    config_c['lr'] = 1e-5
    config_c['save_dir'] = 'training/checkpoints/stage5'
    
    trainer_c = FullMultiTaskTrainer(model, train_loader, val_loader, config_c)
    trainer_c.train()
    
    print("\nğŸ‰ Hybrid æ¨¡å‹è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()
```

---

## ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹å¯¹æ¯”

### 3.1 å¯¹æ¯”è„šæœ¬

```python
# training/scripts/compare_models.py
"""å¯¹æ¯”ä¸åŒæ¨¡å‹çš„æ•ˆæœ"""

import sys
sys.path.append('training/src')

import torch
from pathlib import Path

def compare():
    models = {
        'Stage 2 (ConvNeXt only)': 'training/checkpoints/stage2/best.pth',
        'Stage 4 (Full Multi-task)': 'training/checkpoints/stage4/best.pth',
        'Stage 5 (Hybrid)': 'training/checkpoints/stage5/best.pth',
    }
    
    print("=" * 70)
    print("æ¨¡å‹å¯¹æ¯”")
    print("=" * 70)
    print(f"{'æ¨¡å‹':<30} {'Type Acc':<12} {'Clarity MAE':<12} {'Block MAE':<12}")
    print("-" * 70)
    
    for name, path in models.items():
        if Path(path).exists():
            ckpt = torch.load(path, map_location='cpu')
            history = ckpt.get('history', {})
            
            type_acc = max(history.get('val_type_acc', [0]))
            clarity_mae = min(history.get('val_clarity_mae', [1]))
            block_mae = min(history.get('val_block_mae', [1]))
            
            print(f"{name:<30} {type_acc:<12.4f} {clarity_mae:<12.4f} {block_mae:<12.4f}")
        else:
            print(f"{name:<30} {'(æœªæ‰¾åˆ°)':<12}")
    
    print("=" * 70)

if __name__ == "__main__":
    compare()
```

---

## âœ… è¿‡å…³æ ‡å‡†

- [ ] Hybrid æ¨¡å‹èƒ½æ­£å¸¸è®­ç»ƒ
- [ ] æœºå‹å‡†ç¡®ç‡æ¯”é˜¶æ®µ 4 æå‡ â‰¥ 1%
- [ ] æ¨ç†é€Ÿåº¦å¯æ¥å—ï¼ˆ< 100ms/å¼ ï¼‰
- [ ] GPU æ˜¾å­˜å ç”¨ < 20GB

---

## âŒ ç¦æ­¢äº‹é¡¹

- âŒ ä»å¤´è®­ç»ƒï¼ˆå¿…é¡»åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
- âŒ ä¸€å¼€å§‹å°±è§£å†»å…¨éƒ¨å‚æ•°
- âŒ batch_size å¤ªå¤§å¯¼è‡´æ˜¾å­˜ä¸è¶³

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### æ˜¾å­˜ä¼˜åŒ–

```python
# 1. ä½¿ç”¨æ··åˆç²¾åº¦
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

with autocast():
    outputs = model(images)
    loss = compute_loss(outputs, labels)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()

# 2. æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4
for i, (images, labels) in enumerate(dataloader):
    loss = compute_loss(model(images), labels) / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ç»„åˆ | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ | æ•ˆæœ |
|----------|--------|----------|------|
| convnext_small + swin_small | ~100M | ~10GB | é€‚ä¸­ |
| convnext_base + swin_base | ~180M | ~16GB | è¾ƒå¥½ |
| convnext_large + swin_large | ~400M | ~24GB | æœ€ä½³ï¼ˆéœ€å¤§æ˜¾å­˜ï¼‰ |

---

## ğŸ”œ ä¸‹ä¸€æ­¥

å®Œæˆæ‰€æœ‰æ£€æŸ¥é¡¹åï¼Œè¿›å…¥ [é˜¶æ®µ 6ï¼šOCR æ³¨å†Œå·è¯†åˆ«](stage6_ocr.md)

