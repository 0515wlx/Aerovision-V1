# é˜¶æ®µ 2ï¼šå•ä»»åŠ¡è®­ç»ƒ - æœºå‹åˆ†ç±»

> â±ï¸ é¢„è®¡æ—¶é—´ï¼š2-3 å¤©
> ğŸ¯ ç›®æ ‡ï¼šä½¿ç”¨ ConvNeXt å®Œæˆæœºå‹åˆ†ç±»ä»»åŠ¡ï¼ŒTop-1 å‡†ç¡®ç‡ > 80%
> ğŸ“Œ æ ¸å¿ƒåŸåˆ™ï¼šå…ˆè·‘é€šï¼Œå†ä¼˜åŒ–

---

## ğŸ“‹ æœ¬é˜¶æ®µæ£€æŸ¥æ¸…å•

å®Œæˆæœ¬é˜¶æ®µåï¼Œä½ éœ€è¦æœ‰ï¼š
- [ ] èƒ½æ­£å¸¸åŠ è½½æ•°æ®çš„ Dataset ç±»
- [ ] èƒ½è·‘é€šçš„è®­ç»ƒå¾ªç¯
- [ ] éªŒè¯é›† Top-1 å‡†ç¡®ç‡ > 80%
- [ ] ä¿å­˜çš„æ¨¡å‹æƒé‡æ–‡ä»¶

---

## ç¬¬ä¸€æ­¥ï¼šåˆ›å»º Dataset ç±»

### 1.1 ç†è§£ Dataset

PyTorch çš„ Dataset ç±»è´Ÿè´£ï¼š
1. å‘Šè¯‰è®­ç»ƒå™¨æœ‰å¤šå°‘æ•°æ®ï¼ˆ`__len__`ï¼‰
2. æ ¹æ®ç´¢å¼•è¿”å›ä¸€ä¸ªæ ·æœ¬ï¼ˆ`__getitem__`ï¼‰

```
DataLoader å·¥ä½œæµç¨‹ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DataLoader                                                  â”‚
â”‚    â”‚                                                        â”‚
â”‚    â”œâ”€â”€ ä» Dataset è·å–ç´¢å¼• 0, 1, 2, ..., batch_size-1       â”‚
â”‚    â”œâ”€â”€ è°ƒç”¨ Dataset.__getitem__(idx) è·å–æ¯ä¸ªæ ·æœ¬           â”‚
â”‚    â”œâ”€â”€ å°† batch_size ä¸ªæ ·æœ¬æ‰“åŒ…æˆä¸€ä¸ª batch                 â”‚
â”‚    â””â”€â”€ è¿”å› (images, labels) å¼ é‡                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å®ç° Dataset

```python
# training/src/data/dataset.py
"""èˆªç©ºç…§ç‰‡æ•°æ®é›†"""

import torch
from torch.utils.data import Dataset
from PIL import Image
from pathlib import Path
import pandas as pd
import json

class AircraftDataset(Dataset):
    """
    èˆªç©ºç…§ç‰‡æ•°æ®é›†
    
    Args:
        csv_path: æ ‡æ³¨ CSV æ–‡ä»¶è·¯å¾„
        image_dir: å›¾ç‰‡ç›®å½•
        transform: å›¾ç‰‡å˜æ¢ï¼ˆæ•°æ®å¢å¼ºï¼‰
        task: ä»»åŠ¡ç±»å‹ 'type' | 'airline' | 'multi'
    """
    
    def __init__(
        self,
        csv_path: str,
        image_dir: str,
        transform=None,
        task: str = 'type'
    ):
        self.image_dir = Path(image_dir)
        self.transform = transform
        self.task = task
        
        # è¯»å–æ ‡æ³¨
        self.df = pd.read_csv(csv_path)
        
        # è¿‡æ»¤æ— æ•ˆæ•°æ®
        if task == 'type' or task == 'multi':
            self.df = self.df[self.df['typename'].notna() & (self.df['typename'] != '')]
        
        # é‡ç½®ç´¢å¼•
        self.df = self.df.reset_index(drop=True)
        
        print(f"åŠ è½½æ•°æ®é›†: {len(self.df)} ä¸ªæ ·æœ¬, ä»»åŠ¡: {task}")
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        """è¿”å›ä¸€ä¸ªæ ·æœ¬"""
        row = self.df.iloc[idx]
        
        # åŠ è½½å›¾ç‰‡
        img_path = self.image_dir / row['filename']
        image = Image.open(img_path).convert('RGB')
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        # æ ¹æ®ä»»åŠ¡è¿”å›ä¸åŒçš„æ ‡ç­¾
        if self.task == 'type':
            label = int(row['typeid'])
            return image, label
        
        elif self.task == 'airline':
            label = int(row['airlineid']) if pd.notna(row['airlineid']) else 0
            return image, label
        
        elif self.task == 'multi':
            # å¤šä»»åŠ¡ï¼šè¿”å›å­—å…¸
            labels = {
                'type': int(row['typeid']),
                'airline': int(row['airlineid']) if pd.notna(row['airlineid']) else 0,
            }
            return image, labels
        
        else:
            raise ValueError(f"æœªçŸ¥ä»»åŠ¡: {self.task}")
    
    @property
    def num_types(self):
        """æœºå‹ç±»åˆ«æ•°"""
        return self.df['typeid'].nunique()
    
    @property
    def num_airlines(self):
        """èˆªå¸ç±»åˆ«æ•°"""
        return self.df['airlineid'].nunique()


def get_class_names(labels_dir: str, task: str = 'type'):
    """è·å–ç±»åˆ«åç§°åˆ—è¡¨"""
    labels_path = Path(labels_dir)
    
    if task == 'type':
        json_path = labels_path / 'type_classes.json'
    elif task == 'airline':
        json_path = labels_path / 'airline_classes.json'
    else:
        raise ValueError(f"æœªçŸ¥ä»»åŠ¡: {task}")
    
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    return data['classes']
```

### 1.3 æµ‹è¯• Dataset

```python
# training/scripts/test_dataset.py
"""æµ‹è¯• Dataset æ˜¯å¦æ­£å¸¸å·¥ä½œ"""

import sys
sys.path.append('training/src')

from data.dataset import AircraftDataset
from torchvision import transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

def test_dataset():
    # å®šä¹‰å˜æ¢
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = AircraftDataset(
        csv_path="training/data/processed/aircraft_crop/train.csv",
        image_dir="training/data/processed/aircraft_crop/train",
        transform=transform,
        task='type'
    )
    
    print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"æœºå‹ç±»åˆ«æ•°: {dataset.num_types}")
    
    # è·å–ä¸€ä¸ªæ ·æœ¬
    image, label = dataset[0]
    print(f"å›¾ç‰‡å½¢çŠ¶: {image.shape}")  # [3, 224, 224]
    print(f"æ ‡ç­¾: {label}")
    
    # æµ‹è¯• DataLoader
    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)
    
    for batch_images, batch_labels in dataloader:
        print(f"Batch å›¾ç‰‡å½¢çŠ¶: {batch_images.shape}")  # [16, 3, 224, 224]
        print(f"Batch æ ‡ç­¾å½¢çŠ¶: {batch_labels.shape}")  # [16]
        break
    
    print("\nâœ… Dataset æµ‹è¯•é€šè¿‡ï¼")


if __name__ == "__main__":
    test_dataset()
```

---

## ç¬¬äºŒæ­¥ï¼šæ•°æ®å¢å¼º

### 2.1 ä¸ºä»€ä¹ˆéœ€è¦æ•°æ®å¢å¼ºï¼Ÿ

æ•°æ®å¢å¼ºå¯ä»¥ï¼š
- å¢åŠ æ•°æ®å¤šæ ·æ€§ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
- æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„å˜åŒ–ï¼ˆå…‰ç…§ã€è§’åº¦ç­‰ï¼‰
- è®©æ¨¡å‹å­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾

### 2.2 å®ç°æ•°æ®å¢å¼º

```python
# training/src/data/transforms.py
"""æ•°æ®å˜æ¢ä¸å¢å¼º"""

from torchvision import transforms
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np

def get_train_transform(image_size: int = 224):
    """è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼º"""
    return A.Compose([
        # å°ºå¯¸è°ƒæ•´
        A.LongestMaxSize(max_size=image_size + 32),
        A.RandomCrop(height=image_size, width=image_size),
        
        # ç¿»è½¬ï¼ˆé£æœºå¯ä»¥å·¦å³ç¿»è½¬ï¼Œä½†ä¸è¦ä¸Šä¸‹ç¿»è½¬ï¼‰
        A.HorizontalFlip(p=0.5),
        
        # é¢œè‰²å¢å¼º
        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
        
        # æ¨¡ç³Šï¼ˆæ¨¡æ‹Ÿä¸åŒæ¸…æ™°åº¦ï¼‰
        A.OneOf([
            A.GaussianBlur(blur_limit=(3, 5), p=1.0),
            A.MotionBlur(blur_limit=5, p=1.0),
        ], p=0.2),
        
        # å™ªå£°
        A.GaussNoise(var_limit=(10, 50), p=0.2),
        
        # ä»¿å°„å˜æ¢ï¼ˆè½»å¾®ï¼‰
        A.Affine(
            scale=(0.95, 1.05),
            rotate=(-5, 5),
            shear=(-3, 3),
            p=0.3
        ),
        
        # å½’ä¸€åŒ–
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])


def get_val_transform(image_size: int = 224):
    """éªŒè¯/æµ‹è¯•æ—¶çš„å˜æ¢ï¼ˆä¸åšå¢å¼ºï¼‰"""
    return A.Compose([
        A.LongestMaxSize(max_size=image_size),
        A.PadIfNeeded(min_height=image_size, min_width=image_size, 
                      border_mode=0, value=(128, 128, 128)),
        A.CenterCrop(height=image_size, width=image_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])


class AlbumentationsWrapper:
    """å°† Albumentations å˜æ¢åŒ…è£…æˆ torchvision é£æ ¼"""
    
    def __init__(self, transform):
        self.transform = transform
    
    def __call__(self, image):
        # PIL Image â†’ numpy array
        image = np.array(image)
        # åº”ç”¨å˜æ¢
        augmented = self.transform(image=image)
        return augmented['image']
```

### 2.3 æ›´æ–° Dataset ä½¿ç”¨ Albumentations

```python
# åœ¨ dataset.py ä¸­ä¿®æ”¹ __getitem__

def __getitem__(self, idx):
    row = self.df.iloc[idx]
    
    # åŠ è½½å›¾ç‰‡
    img_path = self.image_dir / row['filename']
    image = Image.open(img_path).convert('RGB')
    
    # è½¬æ¢ä¸º numpy arrayï¼ˆAlbumentations éœ€è¦ï¼‰
    image = np.array(image)
    
    # åº”ç”¨å˜æ¢
    if self.transform:
        augmented = self.transform(image=image)
        image = augmented['image']
    
    # ... è¿”å›æ ‡ç­¾
```

---

## ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºæ¨¡å‹

### 3.1 ç†è§£æ¨¡å‹ç»“æ„

```
ConvNeXt æ¨¡å‹ç»“æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è¾“å…¥: [B, 3, 224, 224]                                     â”‚
â”‚         â†“                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚  â”‚     Backbone         â”‚  â† ConvNeXt é¢„è®­ç»ƒæƒé‡           â”‚
â”‚  â”‚  (ç‰¹å¾æå–)          â”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚         â†“                                                  â”‚
â”‚  ç‰¹å¾: [B, 1024]                                           â”‚
â”‚         â†“                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚  â”‚     Head (åˆ†ç±»å¤´)     â”‚  â† æˆ‘ä»¬è¦è®­ç»ƒçš„éƒ¨åˆ†              â”‚
â”‚  â”‚  Linear(1024, N)     â”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚         â†“                                                  â”‚
â”‚  è¾“å‡º: [B, N]  (N = ç±»åˆ«æ•°)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 å®ç°æ¨¡å‹

```python
# training/src/models/classifier.py
"""åˆ†ç±»æ¨¡å‹"""

import torch
import torch.nn as nn
import timm

class AircraftClassifier(nn.Module):
    """
    é£æœºåˆ†ç±»æ¨¡å‹
    
    Args:
        num_classes: ç±»åˆ«æ•°
        backbone_name: éª¨å¹²ç½‘ç»œåç§°
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        dropout: Dropout æ¯”ä¾‹
    """
    
    def __init__(
        self,
        num_classes: int,
        backbone_name: str = "convnext_base",
        pretrained: bool = True,
        dropout: float = 0.2
    ):
        super().__init__()
        
        # åˆ›å»ºéª¨å¹²ç½‘ç»œ
        self.backbone = timm.create_model(
            backbone_name,
            pretrained=pretrained,
            num_classes=0  # ä¸è¦åˆ†ç±»å¤´ï¼Œåªè¦ç‰¹å¾
        )
        
        # è·å–ç‰¹å¾ç»´åº¦
        self.feature_dim = self.backbone.num_features
        print(f"Backbone: {backbone_name}, ç‰¹å¾ç»´åº¦: {self.feature_dim}")
        
        # åˆ†ç±»å¤´
        self.head = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(self.feature_dim, num_classes)
        )
        
        self.num_classes = num_classes
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        # æå–ç‰¹å¾
        features = self.backbone(x)  # [B, feature_dim]
        
        # åˆ†ç±»
        logits = self.head(features)  # [B, num_classes]
        
        return logits
    
    def get_features(self, x):
        """åªè¿”å›ç‰¹å¾ï¼ˆç”¨äºå¯è§†åŒ–ç­‰ï¼‰"""
        return self.backbone(x)


def create_model(num_classes: int, config: dict = None):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæ¨¡å‹"""
    config = config or {}
    
    return AircraftClassifier(
        num_classes=num_classes,
        backbone_name=config.get('backbone', 'convnext_base'),
        pretrained=config.get('pretrained', True),
        dropout=config.get('dropout', 0.2)
    )
```

### 3.3 æµ‹è¯•æ¨¡å‹

```python
# training/scripts/test_model.py
"""æµ‹è¯•æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ"""

import sys
sys.path.append('training/src')

import torch
from models.classifier import AircraftClassifier

def test_model():
    # åˆ›å»ºæ¨¡å‹
    model = AircraftClassifier(num_classes=10, backbone_name="convnext_base")
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ€»å‚æ•°é‡: {total_params / 1e6:.2f}M")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params / 1e6:.2f}M")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    x = torch.randn(4, 3, 224, 224)
    
    model.eval()
    with torch.no_grad():
        output = model(x)
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    
    # éªŒè¯è¾“å‡º
    assert output.shape == (4, 10), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {output.shape}"
    
    print("\nâœ… æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")


if __name__ == "__main__":
    test_model()
```

---

## ç¬¬å››æ­¥ï¼šè®­ç»ƒå¾ªç¯

### 4.1 åˆ›å»ºè®­ç»ƒå™¨

```python
# training/src/trainers/base_trainer.py
"""åŸºç¡€è®­ç»ƒå™¨"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR
from pathlib import Path
from tqdm import tqdm
import json
from datetime import datetime

class BaseTrainer:
    """
    åŸºç¡€è®­ç»ƒå™¨
    
    Args:
        model: æ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        config: é…ç½®å­—å…¸
    """
    
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        config: dict
    ):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # æ¨¡å‹
        self.model = model.to(self.device)
        
        # æ•°æ®
        self.train_loader = train_loader
        self.val_loader = val_loader
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.CrossEntropyLoss()
        
        # ä¼˜åŒ–å™¨
        self.optimizer = AdamW(
            self.model.parameters(),
            lr=config.get('lr', 1e-4),
            weight_decay=config.get('weight_decay', 0.01)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = CosineAnnealingLR(
            self.optimizer,
            T_max=config.get('epochs', 30),
            eta_min=config.get('lr', 1e-4) * 0.01
        )
        
        # ä¿å­˜ç›®å½•
        self.save_dir = Path(config.get('save_dir', 'training/checkpoints/stage2'))
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # è®­ç»ƒçŠ¶æ€
        self.best_val_acc = 0.0
        self.current_epoch = 0
        self.history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        
        total_loss = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(self.train_loader, desc=f"Epoch {self.current_epoch + 1} [Train]")
        
        for images, labels in pbar:
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(images)
            loss = self.criterion(outputs, labels)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'acc': f"{100. * correct / total:.2f}%"
            })
        
        avg_loss = total_loss / total
        accuracy = correct / total
        
        return avg_loss, accuracy
    
    @torch.no_grad()
    def validate(self):
        """éªŒè¯"""
        self.model.eval()
        
        total_loss = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(self.val_loader, desc=f"Epoch {self.current_epoch + 1} [Val]")
        
        for images, labels in pbar:
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            outputs = self.model(images)
            loss = self.criterion(outputs, labels)
            
            total_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)
        
        avg_loss = total_loss / total
        accuracy = correct / total
        
        return avg_loss, accuracy
    
    def save_checkpoint(self, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_acc': self.best_val_acc,
            'config': self.config,
            'history': self.history
        }
        
        # ä¿å­˜æœ€æ–°çš„
        torch.save(checkpoint, self.save_dir / 'latest.pth')
        
        # ä¿å­˜æœ€å¥½çš„
        if is_best:
            torch.save(checkpoint, self.save_dir / 'best.pth')
            print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (acc: {self.best_val_acc:.4f})")
    
    def train(self, epochs: int = None):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        epochs = epochs or self.config.get('epochs', 30)
        
        print(f"\n{'='*60}")
        print(f"å¼€å§‹è®­ç»ƒ: {epochs} epochs")
        print(f"{'='*60}\n")
        
        for epoch in range(epochs):
            self.current_epoch = epoch
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch()
            
            # éªŒè¯
            val_loss, val_acc = self.validate()
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step()
            current_lr = self.scheduler.get_last_lr()[0]
            
            # è®°å½•å†å²
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)
            
            # æ‰“å°ç»“æœ
            print(f"\nEpoch {epoch + 1}/{epochs}")
            print(f"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
            print(f"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
            print(f"  LR: {current_lr:.6f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            is_best = val_acc > self.best_val_acc
            if is_best:
                self.best_val_acc = val_acc
            self.save_checkpoint(is_best)
        
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.4f}")
        print(f"{'='*60}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        with open(self.save_dir / 'history.json', 'w') as f:
            json.dump(self.history, f, indent=2)
        
        return self.history
```

### 4.2 ä¸»è®­ç»ƒè„šæœ¬

```python
# training/scripts/train_stage2.py
"""é˜¶æ®µ 2 è®­ç»ƒè„šæœ¬ï¼šæœºå‹åˆ†ç±»"""

import sys
sys.path.append('training/src')

import torch
from torch.utils.data import DataLoader

from data.dataset import AircraftDataset
from data.transforms import get_train_transform, get_val_transform, AlbumentationsWrapper
from models.classifier import AircraftClassifier
from trainers.base_trainer import BaseTrainer

def main():
    # ============ é…ç½® ============
    config = {
        # æ•°æ®
        'train_csv': 'training/data/processed/aircraft_crop/train.csv',
        'val_csv': 'training/data/processed/aircraft_crop/val.csv',
        'train_dir': 'training/data/processed/aircraft_crop/train',
        'val_dir': 'training/data/processed/aircraft_crop/val',
        'image_size': 224,
        'batch_size': 32,
        'num_workers': 4,
        
        # æ¨¡å‹
        'backbone': 'convnext_base',
        'pretrained': True,
        'dropout': 0.2,
        
        # è®­ç»ƒ
        'epochs': 30,
        'lr': 1e-4,
        'weight_decay': 0.01,
        
        # ä¿å­˜
        'save_dir': 'training/checkpoints/stage2',
    }
    
    print("é…ç½®:")
    for k, v in config.items():
        print(f"  {k}: {v}")
    
    # ============ æ•°æ® ============
    print("\nåŠ è½½æ•°æ®...")
    
    train_transform = AlbumentationsWrapper(get_train_transform(config['image_size']))
    val_transform = AlbumentationsWrapper(get_val_transform(config['image_size']))
    
    train_dataset = AircraftDataset(
        csv_path=config['train_csv'],
        image_dir=config['train_dir'],
        transform=train_transform,
        task='type'
    )
    
    val_dataset = AircraftDataset(
        csv_path=config['val_csv'],
        image_dir=config['val_dir'],
        transform=val_transform,
        task='type'
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers'],
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True
    )
    
    # ============ æ¨¡å‹ ============
    print("\nåˆ›å»ºæ¨¡å‹...")
    
    num_classes = train_dataset.num_types
    print(f"ç±»åˆ«æ•°: {num_classes}")
    
    model = AircraftClassifier(
        num_classes=num_classes,
        backbone_name=config['backbone'],
        pretrained=config['pretrained'],
        dropout=config['dropout']
    )
    
    # ============ è®­ç»ƒ ============
    trainer = BaseTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=config
    )
    
    history = trainer.train(epochs=config['epochs'])
    
    print("\nè®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()
```

---

## ç¬¬äº”æ­¥ï¼šè¿è¡Œè®­ç»ƒ

### 5.1 å¼€å§‹è®­ç»ƒ

```bash
cd F:\bian\pyproject\Aerovision-V1
python training/scripts/train_stage2.py
```

### 5.2 ç›‘æ§è®­ç»ƒ

ä½ åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š

```
é…ç½®:
  train_csv: training/data/processed/aircraft_crop/train.csv
  ...

åŠ è½½æ•°æ®...
åŠ è½½æ•°æ®é›†: 2500 ä¸ªæ ·æœ¬, ä»»åŠ¡: type
åŠ è½½æ•°æ®é›†: 500 ä¸ªæ ·æœ¬, ä»»åŠ¡: type

åˆ›å»ºæ¨¡å‹...
ç±»åˆ«æ•°: 10
Backbone: convnext_base, ç‰¹å¾ç»´åº¦: 1024

ä½¿ç”¨è®¾å¤‡: cuda

============================================================
å¼€å§‹è®­ç»ƒ: 30 epochs
============================================================

Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:45<00:00, loss: 2.1234, acc: 25.30%]
Epoch 1 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:05<00:00]

Epoch 1/30
  Train Loss: 2.0123, Train Acc: 0.2530
  Val Loss: 1.8234, Val Acc: 0.3450
  LR: 0.000099
  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (acc: 0.3450)

...
```

### 5.3 å¸¸è§é—®é¢˜æ’æŸ¥

**é—®é¢˜ 1ï¼šCUDA out of memory**
```python
# å‡å° batch_size
config['batch_size'] = 16  # æˆ–æ›´å°
```

**é—®é¢˜ 2ï¼šloss ä¸é™**
```python
# æ£€æŸ¥æ•°æ®
for images, labels in train_loader:
    print(f"Images range: [{images.min():.2f}, {images.max():.2f}]")
    print(f"Labels: {labels[:10]}")
    break

# ç¡®ä¿ labels æ˜¯æœ‰æ•ˆçš„ç±»åˆ«ç´¢å¼• (0 åˆ° num_classes-1)
```

**é—®é¢˜ 3ï¼šè®­ç»ƒå¤ªæ…¢**
```python
# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for images, labels in train_loader:
    with autocast():
        outputs = model(images)
        loss = criterion(outputs, labels)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
    optimizer.zero_grad()
```

---

## ç¬¬å…­æ­¥ï¼šè¯„ä¼°æ¨¡å‹

### 6.1 è¯„ä¼°è„šæœ¬

```python
# training/scripts/evaluate_stage2.py
"""è¯„ä¼°é˜¶æ®µ 2 æ¨¡å‹"""

import sys
sys.path.append('training/src')

import torch
from torch.utils.data import DataLoader
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

from data.dataset import AircraftDataset, get_class_names
from data.transforms import get_val_transform, AlbumentationsWrapper
from models.classifier import AircraftClassifier

def evaluate(checkpoint_path: str, test_csv: str, test_dir: str, labels_dir: str):
    """è¯„ä¼°æ¨¡å‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    print(f"åŠ è½½æ¨¡å‹: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    config = checkpoint['config']
    
    # æ•°æ®
    transform = AlbumentationsWrapper(get_val_transform(config.get('image_size', 224)))
    
    test_dataset = AircraftDataset(
        csv_path=test_csv,
        image_dir=test_dir,
        transform=transform,
        task='type'
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=32,
        shuffle=False,
        num_workers=4
    )
    
    # æ¨¡å‹
    num_classes = test_dataset.num_types
    model = AircraftClassifier(
        num_classes=num_classes,
        backbone_name=config.get('backbone', 'convnext_base'),
        pretrained=False
    )
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    # é¢„æµ‹
    all_preds = []
    all_labels = []
    all_probs = []
    
    print("å¼€å§‹è¯„ä¼°...")
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)
            _, preds = outputs.max(1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())
            all_probs.extend(probs.cpu().numpy())
    
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)
    
    # è·å–ç±»åˆ«åç§°
    class_names = get_class_names(labels_dir, task='type')
    
    # æŒ‡æ ‡
    print("\n" + "=" * 60)
    print("åˆ†ç±»æŠ¥å‘Š")
    print("=" * 60)
    print(classification_report(all_labels, all_preds, target_names=class_names))
    
    # Top-1 å’Œ Top-5 å‡†ç¡®ç‡
    top1_correct = (all_preds == all_labels).sum()
    top1_acc = top1_correct / len(all_labels)
    
    top5_preds = np.argsort(all_probs, axis=1)[:, -5:]
    top5_correct = sum(label in pred for label, pred in zip(all_labels, top5_preds))
    top5_acc = top5_correct / len(all_labels)
    
    print(f"\nTop-1 å‡†ç¡®ç‡: {top1_acc:.4f}")
    print(f"Top-5 å‡†ç¡®ç‡: {top5_acc:.4f}")
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('é¢„æµ‹')
    plt.ylabel('çœŸå®')
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.tight_layout()
    
    # ä¿å­˜
    output_dir = Path(checkpoint_path).parent
    plt.savefig(output_dir / 'confusion_matrix.png', dpi=150)
    print(f"\næ··æ·†çŸ©é˜µå·²ä¿å­˜: {output_dir / 'confusion_matrix.png'}")
    
    return top1_acc, top5_acc


if __name__ == "__main__":
    evaluate(
        checkpoint_path="training/checkpoints/stage2/best.pth",
        test_csv="training/data/processed/aircraft_crop/test.csv",
        test_dir="training/data/processed/aircraft_crop/test",
        labels_dir="training/data/labels"
    )
```

---

## âœ… è¿‡å…³æ ‡å‡†

åœ¨è¿›å…¥é˜¶æ®µ 3 ä¹‹å‰ï¼Œç¡®ä¿ï¼š

- [ ] è®­ç»ƒèƒ½æ­£å¸¸è¿è¡Œä¸æŠ¥é”™
- [ ] éªŒè¯é›† Top-1 å‡†ç¡®ç‡ > 80%
- [ ] éªŒè¯é›† Top-5 å‡†ç¡®ç‡ > 95%
- [ ] loss æ›²çº¿æ­£å¸¸ä¸‹é™
- [ ] `training/checkpoints/stage2/best.pth` å·²ä¿å­˜

---

## âŒ ç¦æ­¢äº‹é¡¹

åœ¨æœ¬é˜¶æ®µï¼Œ**ä¸è¦**ï¼š

- âŒ æ·»åŠ å¤šä»»åŠ¡ï¼ˆèˆªå¸ã€æ¸…æ™°åº¦ç­‰ï¼‰
- âŒ å°è¯• Swin æˆ–å…¶ä»–é«˜çº§æ¨¡å‹
- âŒ åš Hybrid æ¨¡å‹
- âŒ è¿‡åº¦è°ƒå‚ï¼ˆå…ˆè·‘é€šï¼ï¼‰

---

## ğŸ’¡ è°ƒå‚å»ºè®®

å¦‚æœå‡†ç¡®ç‡ä¸è¾¾æ ‡ï¼š

1. **é¦–å…ˆæ£€æŸ¥æ•°æ®**
   - å„ç±»åˆ«æ ·æœ¬æ˜¯å¦å‡è¡¡ï¼Ÿ
   - æ ‡æ³¨æ˜¯å¦æœ‰é”™è¯¯ï¼Ÿ

2. **å¢åŠ  epochs**ï¼ˆ30 â†’ 50ï¼‰

3. **è°ƒæ•´å­¦ä¹ ç‡**
   - å¤ªé«˜ï¼šloss éœ‡è¡
   - å¤ªä½ï¼šæ”¶æ•›å¤ªæ…¢
   - è¯•è¯• 3e-4 æˆ– 5e-5

4. **å¢åŠ æ•°æ®å¢å¼º**

---

## ğŸ”œ ä¸‹ä¸€æ­¥

å®Œæˆæ‰€æœ‰æ£€æŸ¥é¡¹åï¼Œè¿›å…¥ [é˜¶æ®µ 3ï¼šå¤š Head è®­ç»ƒ](stage3_multi_head.md)

